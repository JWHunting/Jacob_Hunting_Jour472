# Turn off scientific notation
options(scipen=999)
library(tidyverse)
library(janitor)
library(rio)
library(dplyr)
library(readr)
library(rvest)
homicides <- read.csv("homicide-data.csv") %>%
as.data.frame() %>%
clean_names()
install.packages(lubridate)
library(lubridate)
date_string <- "20100504"
parsed_date <- ymd(date_string)
year_only <- year(parsed_date)
homicides <- homicides %>%
mutate(year = year(ymd(reported_date)))
balt_homicides <- homicides %>%
filter(city == "Baltimore")
balt_homicides151617 <- balt_homicides %>%
mutate(row = row_number()) %>%
filter(year >= 2015)
#1002 reported homicides in 2015, 2016 and 2017. 2015 and 2017 had 365 days and 2016 had 366 days. This is 1096 days.
#1002 homicides divided by 1096 days is about .914, which is about 1 homicide per day over those three years.
#Note to Prof Wells - please let us know if there is a different way that you would want us to filter for year. We were unsure how to split up the text, so we found the row with the earliest 2015 homicide and filtered for all subsequent homicides through assigning numbers to rows.
balt_hom_yr <- balt_homicides %>%
count(disposition, year) %>%
group_by(disposition, year) %>%
filter(disposition == "Closed by arrest")
balt_hom_yr %>%
ggplot(aes(x=year, y=n, weight=n, fill=n))+
geom_col()
#This graph shows that arrests for homicides went down.
#Although we do not exactly agree that they plumpted.
balt_homicides2014 <- balt_homicides %>%
filter(year == "2014") %>%
count(disposition) %>%
group_by(disposition)
sum(balt_homicides2014$n)
#The total amount of homicides in 2014 in Baltimore was 211. There were 86 arrests. 86 divded by 211 is .407 which is about 41%
balt_homicides2017 <- balt_homicides %>%
filter(year == "2017") %>%
count(disposition) %>%
group_by(disposition)
sum(balt_homicides2017$n)
#The total amount of homicides in 2014 in Baltimore was 340. There were 93 arrests. 93 divided by 340 is .27 which is 27%.
#41% compared to 27% is indeed a 14% drop.
balt_homicides151617_dispo <- balt_homicides151617 %>%
count(disposition) %>%
group_by(disposition)
#252 of the homicides between 2015-2017 were closed by an arrest.
View(balt_hom_yr)
View(balt_homicides2014)
balt_homicides2014 <- balt_homicides %>%
filter(year == "2014") %>%
count(disposition) %>%
group_by(disposition) %>%
mutate(n/sum(balt_homicides2014))
balt_homicides2014 <- balt_homicides %>%
filter(year == "2014") %>%
count(disposition) %>%
group_by(disposition) %>%
mutate(n/sum(balt_homicides2014$n)) %>%
sum(balt_homicides2014$n)
balt_homicides2014 <- balt_homicides %>%
filter(year == "2014") %>%
count(disposition) %>%
group_by(disposition) %>%
mutate(n/sum(balt_homicides2014$n))
#The total amount of homicides in 2014 in Baltimore was 211. There were 86 arrests. 86 dived by 211 is .407 which is about 41%
balt_homicides2014 <- balt_homicides %>%
filter(year == "2014") %>%
count(disposition) %>%
group_by(disposition) %>%
mutate(n/sum(balt_homicides2014$n)*100)
#The total amount of homicides in 2014 in Baltimore was 211. There were 86 arrests. 86 dived by 211 is .407 which is about 41%
View(balt_homicides2017)
balt_homicides2017 <- balt_homicides %>%
filter(year == "2017") %>%
count(disposition) %>%
group_by(disposition) %>%
mutate(n/sum(balt_homicides2017$n)*100)
#The total amount of homicides in 2014 in Baltimore was 340. There were 93 arrests. 93 divided by 340 is .27 which is 27%.
#41% compared to 27% is indeed a 14% drop.
balt_homicides151617_dispo <- balt_homicides151617 %>%
count(disposition) %>%
group_by(disposition)
#252 of the homicides between 2015-2017 were closed by an arrest.
View(balt_homicides151617_dispo)
# Turn off scientific notation
options(scipen=999)
library(tidyverse)
library(janitor)
library(rio)
library(dplyr)
library(readr)
library(rvest)
library(sf)
library(leaflet)
homicides <- read.csv("homicide-data.csv") %>%
as.data.frame() %>%
clean_names()
install.packages(lubridate)
library(lubridate)
date_string <- "20100504"
parsed_date <- ymd(date_string)
year_only <- year(parsed_date)
homicides <- homicides %>%
mutate(year = year(ymd(reported_date)))
balt_homicides <- homicides %>%
filter(city == "Baltimore")
balt_homicides151617 <- balt_homicides %>%
mutate(row = row_number()) %>%
filter(year >= 2015)
#1002 reported homicides in 2015, 2016 and 2017. 2015 and 2017 had 365 days and 2016 had 366 days. This is 1096 days.
count(balt_homicides151617)/(365+365+366)
#1002 homicides divided by 1096 days is about .914, which is about 1 homicide per day over those three years.
balt_homicides_yr_dispo <- balt_homicides %>%
count(disposition, year) %>%
group_by(disposition, year) %>%
filter(disposition == "Closed by arrest") %>%
mutate(arrests = n) %>%
data_frame()
balt_homicides_yr <- balt_homicides %>%
count(year) %>%
group_by(year)
balt_homicides_yr <- balt_homicides_yr %>%
mutate(total = n) %>%
data_frame()
balt_homicides_yr <- balt_homicides_yr %>%
inner_join(balt_homicides_yr_dispo, by="year") %>%
select(year, total, arrests) %>%
mutate(pct_arrest = arrests/total*100)
balt_homicides_yr %>%
ggplot(aes(x=year, y=pct_arrest, weight=pct_arrest, fill=pct_arrest))+
geom_col()
#This graph shows that arrests for homicides have indeed plummeted. The table balt_homicides_yr shows that in 2014, 41% of homicides resulted in arrests and then in 2016, 2017 and 2018, arrests were at 25%, 23% and 27% respectively.
balt_homicides2014 <- balt_homicides %>%
filter(year == "2014") %>%
count(disposition) %>%
group_by(disposition)
balt_homicides2014_arrests <- balt_homicides2014 %>%
filter(disposition == "Closed by arrest")
sum(balt_homicides2014_arrests$n)/sum(balt_homicides2014$n)
#The total amount of homicides in 2014 in Baltimore was 211. There were 86 arrests. 86 divded by 211 is .407 which is about 41%
balt_homicides2017 <- balt_homicides %>%
filter(year == "2017") %>%
count(disposition) %>%
group_by(disposition)
balt_homicides2017_arrests <- balt_homicides2017 %>%
filter(disposition == "Closed by arrest")
sum(balt_homicides2017_arrests$n)/sum(balt_homicides2017$n)
sum(balt_homicides2014_arrests$n)/sum(balt_homicides2014$n) - sum(balt_homicides2017_arrests$n)/sum(balt_homicides2017$n)
#The total amount of homicides in 2017 in Baltimore was 340. There were 93 arrests. 93 divided by 340 is .27 which is 27%.
#41% compared to 27% is indeed a 14% drop.
balt_homicides151617_dispo <- balt_homicides151617 %>%
count(disposition) %>%
group_by(disposition)
balt_homicides151617_arrests <- balt_homicides151617_dispo %>%
filter(disposition == "Closed by arrest")
#252 of the homicides between 2015-2017 were closed by an arrest.
#Read new files
balt_tract_shapefiles <- read_rds("baltimore_tract_shapefiles.rds")
balt_homicides151617_dispo <- balt_homicides151617 %>%
count(disposition) %>%
group_by(disposition)
balt_homicides151617_arrests <- balt_homicides151617_dispo %>%
filter(disposition == "Closed by arrest")
#252 of the homicides between 2015-2017 were closed by an arrest.
#Read new files
balt_tract_shapefiles <- read_rds("baltimore_tract_shapefiles.rds")
sandtown_homicides <- balt_homicides_geo %>%
clean_names() %>%
filter(community_statistical_area_2020 == "Sandtown-Winchester/Harlem Park")
#Read new files
balt_tract_shapefiles <- read_rds("baltimore_tract_shapefiles.rds")
balt_census_crosswalk <- read_csv("balt_census_crosswalks_2020.csv")
#Read new files
balt_tract_shapefiles <- read_rds("baltimore_tract_shapefiles.rds")
balt_census_crosswalk <- read_csv("balt_census_crosswalks_2020.csv")
#Read new files
balt_tract_shapefiles <- read_rds("baltimore_tract_shapefiles.rds")
balt_census_crosswalk <- read_csv("balt_census_crosswalks_2020.csv")
#Set up geo files
balt_census_crosswalk <- balt_census_crosswalk %>%
mutate(geoid=as.character(GEOID_Tract_2020))
#making files shapefiles
balt_geo_neighb <- balt_census_crosswalk %>%
inner_join(balt_tract_shapefiles, by=c("geoid")) %>%
st_as_sf()
balt_homicides_sf <- balt_homicides %>%
st_as_sf(
coords = c("lon","lat"),
crs="NAD83")
#map
ggplot() +
geom_sf(data=balt_geo_neighb) +
geom_sf(data=balt_homicides_sf)
#Although this graph is not necessary to answer the question, it is interesting in that it illustrates that the homicides in Baltimore from 2007-2017 lay mostly on the Black Butterfly, which is Baltimore's historically Black neighborhoods. This is an observation of the data that we found was overlooked by The Washington Post, but it is important for understanding the racial dynamic of Baltimore City and its neighborhoods.
#spacial join
balt_homicides_geo <- balt_homicides_sf%>%
st_join(balt_geo_neighb)
sandtown_homicides <- balt_homicides_geo %>%
clean_names() %>%
filter(community_statistical_area_2020 == "Sandtown-Winchester/Harlem Park")
sandtown_homicides_yr <- sandtown_homicides %>%
count(year) %>%
group_by(year)
sandtown_homicides_yr_before <- sandtown_homicides_yr %>%
filter(year >= "2012",
year <= "2014")
sum(sandtown_homicides_yr_before$n)
#35 homicides from 2012-2014
sandtown_homicides_yr_after <- sandtown_homicides_yr %>%
filter(year >= "2015",
year <= "2017")
sum(sandtown_homicides_yr_after$n)
#56 homicides from 2015-2017
(sum(sandtown_homicides_yr_after$n)) - (sum(sandtown_homicides_yr_before$n))
#Our answer was 21, although The Washington Post found 22.
#Our hypothesis for why this number is one off has to do with the BNIA containers for multipolygons of neighborhoods that we used. Defining Baltimore neighborhoods is something that does not have an exact statistical definition. The Baltimore Neighborhood Indicator's Alliance community statistical areas is one of many ways to define Baltimore neighborhoods. This is not a definition that is used across the whole statistical community, so The Washington Post probably used a container of neighborhoods different from the BNIA which had a slight variation. So one of the homicides near a borderline may have been in a different neighborhood by their containers and neighborhoods.
swbalt_homicides <- balt_homicides_geo %>%
clean_names() %>%
filter(community_statistical_area_2020 == "Southwest Baltimore")
swbalt_homicides_yr <- swbalt_homicides %>%
count(year) %>%
group_by(year)
swbalt_homicides_yr_before <- swbalt_homicides_yr %>%
filter(year >= "2012",
year <= "2014")
sum(swbalt_homicides_yr_before$n)
#37 homicides from 2012-2014
swbalt_homicides_yr_after <- swbalt_homicides_yr %>%
filter(year >= "2015",
year <= "2017")
sum(swbalt_homicides_yr_after$n)
#73 homicides from 2015-2017
sum(swbalt_homicides_yr_after$n) - sum(swbalt_homicides_yr_before$n)
#The Washington Post reported 35, but we found 36.
#Our hypothesis for why this number is one off has to do with the BNIA containers for multipolygons of neighborhoods that we used. Defining Baltimore neighborhoods is something that does not have an exact statistical definition. The Baltimore Neighborhood Indicator's Alliance community statistical areas is one of many ways to define Baltimore neighborhoods. This is not a definition that is used across the whole statistical community, so The Washington Post probably used a container of neighborhoods different from the BNIA which had a slight variation. So one of the homicides near a borderline may have been in a different neighborhood by their containers and neighborhoods.
grrosemont_homicides <- balt_homicides_geo %>%
clean_names() %>%
filter(community_statistical_area_2020 == "Greater Rosemont")
grrosemont_homicides_yr <- grrosemont_homicides %>%
count(year) %>%
group_by(year)
grrosemont_homicides_yr_before <- grrosemont_homicides_yr %>%
filter(year >= "2012",
year <= "2014")
sum(grrosemont_homicides_yr_before$n)
#35 homicides from 2012-2014
grrosemont_homicides_yr_after <- grrosemont_homicides_yr %>%
filter(year >= "2015",
year <= "2017")
sum(grrosemont_homicides_yr_after$n)
#62 homicides from 2015-2017
sum(grrosemont_homicides_yr_after$n) - sum(grrosemont_homicides_yr_before$n)
#The Washington Post reported 26, but we found 27.
#Our hypothesis for why this number is one off has to do with the BNIA containers for multipolygons of neighborhoods that we used. Defining Baltimore neighborhoods is something that does not have an exact statistical definition. The Baltimore Neighborhood Indicator's Alliance community statistical areas is one of many ways to define Baltimore neighborhoods. This is not a definition that is used across the whole statistical community, so The Washington Post probably used a container of neighborhoods different from the BNIA which had a slight variation. So one of the homicides near a borderline may have been in a different neighborhood by their containers and neighborhoods.
balt_homicides_yr_dispo <- balt_homicides %>%
count(disposition, year) %>%
group_by(disposition, year) %>%
filter(disposition == "Closed by arrest") %>%
mutate(arrests = n) %>%
data_frame()
balt_homicides_yr <- balt_homicides %>%
count(year) %>%
group_by(year)
balt_homicides_yr <- balt_homicides_yr %>%
mutate(total = n) %>%
data_frame()
balt_homicides_arrests <- balt_homicides_yr %>%
inner_join(balt_homicides_yr_dispo, by="year") %>%
select(year, total, arrests)
balt_homicides_arrests_151617 <- balt_homicides_arrests %>%
filter(year >= "2015",
year <= "2017")
sum(balt_homicides_arrests_151617$arrests)/sum(balt_homicides_arrests_151617$total)*100
#Police made arrests in 25.1497% of arrests in the city in the three years after the death of Gray.
sandtown_homicides_yr_dispo <- sandtown_homicides %>%
count(disposition, year) %>%
group_by(disposition, year) %>%
filter(disposition == "Closed by arrest") %>%
mutate(arrests = n) %>%
data_frame()
sandtown_homicides_yr <- sandtown_homicides_yr %>%
mutate(total = n) %>%
data_frame()
sandtown_homicides_arrests <- sandtown_homicides_yr %>%
inner_join(sandtown_homicides_yr_dispo, by="year") %>%
select(year, total, arrests)
sandtown_homicides_arrests_151617 <- sandtown_homicides_arrests %>%
filter(year >= "2015",
year <= "2017")
sum(sandtown_homicides_arrests_151617$arrests)/sum(sandtown_homicides_arrests_151617$total)*100
#Police made arrests in 16.07143% of arrests in Sandtown-Winchester in the three years after the death of Gray.
View(grrosemont_homicides_yr_after)
